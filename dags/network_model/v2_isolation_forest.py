# -*- coding: utf-8 -*-
"""v2_isolation_forest.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aBDLtsZBFQn3FEgH_GtqKSKuYZi2VOSd
"""

from sklearn.ensemble import IsolationForest
import numpy as np
import joblib

from google.colab import data_table
data_table.enable_dataframe_formatter()

from google.colab import auth
auth.authenticate_user()
print('Authenticated')

"""# Connecting to Bigquery"""

#@title Ambil Data Cloud/BigQuery Project ID
project_id = 'stately-node-363801' #@param{type:"string"}

# Package used for interfacing w/ BigQuery from Python
from google.cloud import bigquery

# Create BigQuery client
bq_client = bigquery.Client(project = project_id)

# Commented out IPython magic to ensure Python compatibility.
# %%bigquery network_data --project {project_id}
# 
# SELECT
# *
# FROM `stately-node-363801.network.network_data_silver`

# network_data

# Select the features used
data = network_data[['label', 'duration', 'protocol', 'source_port', 'direction', 'destination_port', 'state']].copy()

#cara 1
# Initialize the Isolation Forest model
iso_forest = IsolationForest(contamination=0.1, random_state=42)

# Fit the model
iso_forest.fit(data)

# Predict anomalies
data['anomaly'] = iso_forest.predict(data)

# Count the number of anomalies
# print(data['anomaly'].value_counts())

"""# Save Model as pickle file"""

joblib.dump(iso_forest, 'isolation_forest_model.pkl')

print("Model training completed and saved to isolation_forest_model.pkl")