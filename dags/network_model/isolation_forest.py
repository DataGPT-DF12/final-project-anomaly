# -*- coding: utf-8 -*-
"""isolation_forest.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11AqwCpY0t3AHGjXE-nMBZLoVcz6FQFXY
"""

import pandas as pd
import numpy as np
import ipaddress
import re
import seaborn as sn
from sklearn.preprocessing import LabelEncoder


import matplotlib.pyplot as plt

from sklearn.ensemble import IsolationForest
from sklearn.model_selection import train_test_split
from sklearn.ensemble import IsolationForest
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.decomposition import PCA
import joblib

from google.colab import data_table
data_table.enable_dataframe_formatter()

from google.colab import auth
auth.authenticate_user()
print('Authenticated')

"""# Connecting to Bigquery"""

#@title Ambil Data Cloud/BigQuery Project ID
project_id = 'stately-node-363801' #@param{type:"string"}

# Package used for interfacing w/ BigQuery from Python
from google.cloud import bigquery

# Create BigQuery client
bq_client = bigquery.Client(project = project_id)

# Commented out IPython magic to ensure Python compatibility.
# %%bigquery network_data --project {project_id}
# 
# SELECT
# *
# FROM `stately-node-363801.network.network_data_silver`

# network_data

#cara 1
# Initialize the Isolation Forest model
iso_forest = IsolationForest(contamination=0.1, random_state=42)

# Fit the model
iso_forest.fit(network_data)

# Predict anomalies
network_data['anomaly'] = iso_forest.predict(network_data)

# Count the number of anomalies
# print(network_data['anomaly'].value_counts())

"""# Save Model as pickle file"""

joblib.dump(iso_forest, 'isolation_forest_model.pkl')

print("Model training completed and saved to isolation_forest_model.pkl")